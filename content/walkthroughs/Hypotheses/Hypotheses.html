---
title: "Testing Hypotheses"
linktitle: "Week 10: Testing Hypotheses"
output:
  blogdown::html_page:
    toc: true
menu:
  lesson:
    parent: Walkthroughs
    weight: 2
type: docs
weight: 3
editor_options: 
  chunk_output_type: console
---

<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>
<script src="/rmarkdown-libs/kePrint/kePrint.js"></script>
<link href="/rmarkdown-libs/lightable/lightable.css" rel="stylesheet" />

<div id="TOC">
<ul>
<li><a href="#preparation">Preparation</a></li>
<li><a href="#purpose">Purpose</a><ul>
<li><a href="#objectives">Objectives</a></li>
<li><a href="#packages">Packages</a></li>
</ul></li>
<li><a href="#the-t.test-command">The <code>t.test()</code> Command</a></li>
<li><a href="#its-all-about-the-assumptions">It’s All About the Assumptions</a></li>
<li><a href="#example">Example</a><ul>
<li><a href="#midwest-data-set-from-ggplot2">Midwest Data Set from ggplot2</a></li>
<li><a href="#one-sample-t-test">One-sample <em>t</em>-test</a></li>
<li><a href="#two-sample-t-test">Two-sample <em>t</em>-test</a></li>
<li><a href="#the-paired-t-test">The Paired <em>t</em>-test</a></li>
</ul></li>
</ul>
</div>

<div id="preparation" class="section level2">
<h2>Preparation</h2>
<p>Download a <a href="/walkthroughs/Hypotheses.R" target="_blank">script</a> file of just the R chunks used in this walkthrough.</p>
</div>
<div id="purpose" class="section level2">
<h2>Purpose</h2>
<p>One of the most common tests in statistics, the <em>t</em>-test, is used to determine whether the means of two groups are equal to each other. The assumption for the test is that both groups are sampled from normal distributions with equal variances. The null hypothesis is that the two means are equal, and the alternative is that they are not. It is known that under the null hypothesis, we can calculate a <em>t</em>-statistic that will follow a <em>t</em>-distribution with <span class="math inline">\(n_1+n_2 - 2\)</span> degrees of freedom. There is also a widely used modification of the <em>t</em>-test, known as Welch’s <em>t</em>-test that adjusts the number of degrees of freedom when the variances are thought not to be equal to each other. This tutorial covers the basics of performing <em>t</em>-tests in <code>R</code>.</p>
<div id="objectives" class="section level3">
<h3>Objectives</h3>
<p>This guide serves as an introduction to performing <em>t</em>-tests to compare two groups. Here’s what we’ll</p>
<ul>
<li>introduce the <code>midwest</code> example data set</li>
<li>use the <code>patchwork</code> package</li>
<li>associate the <em>t</em>-test in R by using the overarching command <code>t.test()</code></li>
<li>provide some familiarity with the variants of the <em>t</em>-test:
<ul>
<li><strong>One-sample <em>t</em>-tests</strong>: Compare the sample mean with a known value, when the variance of the population is unknown</li>
<li><strong>Two-sample <em>t</em>-tests</strong>: Compare the means of two groups under the assumption that both samples are random, independent, and normally distributed with unknown but equal variances</li>
<li><strong>Paired <em>t</em>-tests</strong>: Compare the means of two sets of paired samples, taken from two populations with unknown variance</li>
</ul></li>
</ul>
</div>
<div id="packages" class="section level3">
<h3>Packages</h3>
<p>There is one package we’ll be using that you probably do not have: the <code>patchwork</code> package which is a tidy update to the base R <code>grid</code> and <code>gridExtra</code> packages. If you do not have it yet, make sure to install it first using</p>
<pre class="r"><code>install.packages(&#39;patchwork&#39;)</code></pre>
<p>Now please load up the following packages</p>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──</code></pre>
<pre><code>## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
## ✓ tibble  3.0.4     ✓ dplyr   1.0.2
## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
## ✓ readr   1.4.0     ✓ forcats 0.5.0</code></pre>
<pre><code>## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter()     masks stats::filter()
## x dplyr::group_rows() masks kableExtra::group_rows()
## x dplyr::lag()        masks stats::lag()</code></pre>
<pre class="r"><code>library(patchwork)</code></pre>
</div>
</div>
<div id="the-t.test-command" class="section level2">
<h2>The <code>t.test()</code> Command</h2>
<p>The <code>t.test()</code> function can be used to perform both one and two sample <em>t</em>-tests on vectors of data. The function contains a variety of arguments and is called as follows:</p>
<pre class="r"><code>t.test(x, y = NULL, alternative = c(&quot;two.sided&quot;, &quot;less&quot;, &quot;greater&quot;), mu = 0, 
       paired = FALSE, var.equal = FALSE, conf.level = 0.95)</code></pre>
<p>Each of the letters - aka arguments - inside of the command are specifically defined:</p>
<center>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
Options that you can use in t.test()
</th>
<th style="text-align:left;">
What it is…
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;width: 20em; ">
<code>x</code>
</td>
<td style="text-align:left;width: 30em; ">
a <em>numeric vector</em> from a data set
</td>
</tr>
<tr>
<td style="text-align:center;width: 20em; ">
<code>y</code>
</td>
<td style="text-align:left;width: 30em; ">
an optional <em>numeric vector</em> from a data set
</td>
</tr>
<tr>
<td style="text-align:center;width: 20em; ">
<code>mu</code>
</td>
<td style="text-align:left;width: 30em; ">
a number indicating the true value of the mean
</td>
</tr>
<tr>
<td style="text-align:center;width: 20em; ">
<code>alternative</code>
</td>
<td style="text-align:left;width: 30em; ">
preference on type of test you wish to run
</td>
</tr>
<tr>
<td style="text-align:center;width: 20em; ">
<code>paired</code>
</td>
<td style="text-align:left;width: 30em; ">
preference on whether you wish to perform a paired <em>t</em>-test
</td>
</tr>
<tr>
<td style="text-align:center;width: 20em; ">
<code>var.equa</code>l
</td>
<td style="text-align:left;width: 30em; ">
indicates whether or not to assume equal variances when performing a two-sample <em>t</em>-test
</td>
</tr>
<tr>
<td style="text-align:center;width: 20em; ">
<code>conf.level</code>
</td>
<td style="text-align:left;width: 30em; ">
the confidence level of the reported confidence interval
</td>
</tr>
</tbody>
</table>
</center>
<p>Below are a few things to note about the <code>t.test()</code> command before we move on that can drastically affect your outcomes if you are not aware of them.</p>
<ul>
<li>If the variable <code>y</code> is
<ul>
<li><em>excluded</em>, <code>t.test()</code> will run as a <strong>one-sample <em>t</em>-test</strong></li>
<li><em>included</em>, <code>t.test()</code> will run as a <strong>two-sample <em>t</em>-test</strong></li>
</ul></li>
<li>The default <code>t.test()</code> command will run as a two-sided <em>t</em>-test. However you can perform an alternative hypothesis by changing the <code>alternative</code> argument to:
<ul>
<li>“<code>greater</code>”, or</li>
<li>“<code>less</code>”.
For example</li>
</ul></li>
</ul>
<pre class="r"><code> t.test(x, alternative = &quot;greater&quot;, mu = 47)</code></pre>
<p>performs a one-sample <em>t</em>-test on the data contained in x where the
- null hypothesis is <span class="math inline">\(\mu = 47\)</span>, and the
- alternative hypothesis is <span class="math inline">\(\mu &gt; 47\)</span>.</p>
<ul>
<li><p>The <code>paired</code> argument has a default setting of <code>FALSE</code> indicating that a paired <em>t</em>-test should not be run. If you wish to run a paired <em>t</em>-test, this can be done by changing the setting to <code>TRUE</code>.</p></li>
<li><p>The <code>var.equals</code> argument has a default setting of <code>FALSE</code> indicating unequal variances ans applies the Welsch approximation to the degrees of freedom. If you wish to have equal variances, this can be done by changing the setting to <code>TRUE</code>.</p></li>
<li><p>The <code>conf.level</code> argument is set to 95%, or where <span class="math inline">\(\alpha = 0.05\)</span>. The confidence interval is determined by</p>
<ul>
<li><span class="math inline">\(\mu\)</span> for the one-sample <em>t</em>-test, and</li>
<li><span class="math inline">\(\mu_1-\mu_2\)</span> for the one-sample <em>t</em>-test.</li>
</ul></li>
</ul>
<p>On a final note, the <code>wilcox.test()</code> option provides the same basic functionality and arguments, but with the idea that we <strong>do not want to assume the data to follow a normal distribution</strong>. This is often the case for samples but at this time, we will assume that the data that is normally distributed. Understanding the <code>wilcox.test()</code> function is beyond the scope of this course.</p>
</div>
<div id="its-all-about-the-assumptions" class="section level2">
<h2>It’s All About the Assumptions</h2>
<p>Before we can move forward in the exploration of the <em>t</em>-test, we must first make sure that any data that we use adheres to the test assumptions.</p>
<ul>
<li><strong>Assumption #1: Random sampling</strong>: Data is derived from random sampling.</li>
<li><strong>Assumption #2: Independent observations</strong>: Observations are independent from one another.</li>
<li><strong>Assumption #3: Normality</strong>: Observations are from a normally distributed population.</li>
<li><strong>Assumption #4: Homogeneity</strong>: If more than one population is sampled from, then the populations have equal variances (also known as <strong><em>homogeneity of variances</em></strong>)</li>
</ul>
</div>
<div id="example" class="section level2">
<h2>Example</h2>
<div id="midwest-data-set-from-ggplot2" class="section level3">
<h3>Midwest Data Set from ggplot2</h3>
<p>The <code>ggplot2</code> package has some test data built in, though you may not find them that exciting which is the reason we tend to use real-world data that is more connected to the social sciences and education. However, in this walkthrough, we will be using one of the <code>ggplot2</code> data sets named <code>midwest</code>. This data set contains contains county-level data for 5 states: IL, IN, MI, OH, &amp; WI derived from the 2010 U.S. Census. I’ll leave the level of excitement up to you. When you lead up <code>tidyverse</code>, or more specifically <code>ggplot2</code>, the <code>midwest</code> data sets is also loaded automatically. Let’s take a look at it:</p>
<pre class="r"><code>head(midwest)</code></pre>
<pre><code>## # A tibble: 6 x 28
##     PID county state  area poptotal popdensity popwhite popblack popamerindian
##   &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;
## 1   561 ADAMS  IL    0.052    66090      1271.    63917     1702            98
## 2   562 ALEXA… IL    0.014    10626       759      7054     3496            19
## 3   563 BOND   IL    0.022    14991       681.    14477      429            35
## 4   564 BOONE  IL    0.017    30806      1812.    29344      127            46
## 5   565 BROWN  IL    0.018     5836       324.     5264      547            14
## 6   566 BUREAU IL    0.05     35688       714.    35157       50            65
## # … with 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,
## #   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,
## #   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,
## #   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,
## #   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,
## #   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;</code></pre>
</div>
<div id="one-sample-t-test" class="section level3">
<h3>One-sample <em>t</em>-test</h3>
<p>The one-sample <em>t</em>-test compares a sample’s mean with a known value, when the variance of the population is unknown. Consider we want to assess the percent of college educated adults in the midwest and compare it to a certain value. For example, let’s assume the nation-wide average of college educated adults is approximately <a href="%22https://www.census.gov/data/tables/2018/demo/education-attainment/cps-detailed-tables.html%22">37% (Bachelor’s degree or higher)</a> and we want to see if the midwest mean is significantly different than the national average; in particular we want to test if the midwest average is less than the national average.</p>
<p>Let’s first take a look at how the data looks (important!) and some descriptive statistics:</p>
<pre class="r"><code>head(midwest$percollege, 10)</code></pre>
<pre><code>##  [1] 19.63139 11.24331 17.03382 17.27895 14.47600 18.90462 11.91739 16.19712
##  [9] 14.10765 41.29581</code></pre>
<pre class="r"><code>summary(midwest$percollege)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   7.336  14.114  16.798  18.273  20.550  48.079</code></pre>
<p>and then plot it to see the distribution:</p>
<pre class="r"><code>p1 &lt;- ggplot(midwest, aes(x = percollege)) + 
        geom_histogram(aes(fill = ..count..), color = &quot;#ccccaa&quot;) +
        scale_fill_gradient(&quot;Frequency&quot;, low = &quot;#5cb85c&quot;, high = &quot;#428bca&quot;) +
        theme_minimal() +
        theme(legend.position = &quot;bottom&quot;,
              legend.direction = &quot;horizontal&quot;)



p2 &lt;- ggplot(midwest, aes(x = percollege)) + 
        geom_histogram(aes(fill = ..count..), color = &quot;#ccccaa&quot;) +
        scale_fill_gradient(&quot;Frequency&quot;, low = &quot;#5cb85c&quot;, high = &quot;#428bca&quot;) +
        scale_x_log10() +
        theme_minimal() +
        theme(legend.position = &quot;bottom&quot;,
              legend.direction = &quot;horizontal&quot;)


p1 + p2</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="/walkthroughs/Hypotheses/Hypotheses_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>To test if the midwest average is less than the national average, we’ll perform three tests. First we test with a normal <em>t</em>-test without any distribution transformations. The results below show a <em>p</em>-value &lt; .001 supporting the alternative hypothesis that “the true mean is less than 37%.”</p>
<pre class="r"><code>t.test(midwest$percollege, mu = 37, alternative = &quot;less&quot;)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  midwest$percollege
## t = -62.518, df = 436, p-value &lt; 2.2e-16
## alternative hypothesis: true mean is less than 37
## 95 percent confidence interval:
##     -Inf 18.7665
## sample estimates:
## mean of x 
##  18.27274</code></pre>
<p>Alternatively, due to the non-normality concerns we can perform this test in another way to ensure our results are not being biased due to assumption violations. We can perform the <em>t</em>-test and transform our data. The results support our initial conclusion that the percent of college educated adults in the midwest is statistically less than the nationwide average.</p>
<pre class="r"><code>t.test(log(midwest$percollege), mu = log(37), alternative = &quot;less&quot;)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  log(midwest$percollege)
## t = -51.37, df = 436, p-value &lt; 2.2e-16
## alternative hypothesis: true mean is less than 3.610918
## 95 percent confidence interval:
##      -Inf 2.879812
## sample estimates:
## mean of x 
##  2.855574</code></pre>
</div>
<div id="two-sample-t-test" class="section level3">
<h3>Two-sample <em>t</em>-test</h3>
<p>Now let’s say we want to compare the differences between the average percent of college educated adults in Ohio versus Michigan. Here, we want to perform a two-sample <em>t</em>-test. So let’s first do some data wrangling…</p>
<pre class="r"><code>ohio_mi &lt;- midwest %&gt;%
        filter(state == &quot;OH&quot; | state == &quot;MI&quot;) %&gt;%
        select(state, percollege)</code></pre>
<p>…and find some descriptive statistics</p>
<ul>
<li>First for Ohio:</li>
</ul>
<pre class="r"><code># Ohio summary stats
summary(ohio_mi %&gt;% 
          filter(state == &quot;OH&quot;) %&gt;% 
          .$percollege)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   7.913  13.089  15.462  16.890  18.995  32.205</code></pre>
<ul>
<li>and then for Michigan:</li>
</ul>
<pre class="r"><code># Ohio summary stats
summary(ohio_mi %&gt;% 
          filter(state == &quot;MI&quot;) %&gt;% 
          .$percollege)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   11.31   14.61   17.43   19.42   21.31   48.08</code></pre>
<p>We can see Ohio appears to have slightly less college educated adults than Michigan but the graphic doesn’t tell us if it is statistically significant or not.</p>
<pre class="r"><code>ggplot(ohio_mi, aes(x = state, y = percollege, fill = state)) +
        geom_boxplot(alpha = 0.5) +
        scale_fill_manual(values = c(&quot;#00274C&quot;, &quot;#BB0000&quot;)) +
        theme_minimal() </code></pre>
<p><img src="/walkthroughs/Hypotheses/Hypotheses_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>We can also once again see similar skewness within the sample distributions by running the following.</p>
<pre class="r"><code>p3 &lt;- ggplot(ohio_mi, aes(x = percollege)) +
        geom_histogram(aes(fill = ..count..), color = &quot;#ccccaa&quot;) +
        scale_fill_gradient(&quot;Frequency&quot;, low = &quot;#5cb85c&quot;, high = &quot;#428bca&quot;) +
        facet_wrap(~ state) +
        theme_minimal() +
        theme(legend.position = &quot;bottom&quot;,
              legend.direction = &quot;horizontal&quot;)
    

p4 &lt;- ggplot(ohio_mi, aes(x = percollege)) +
        geom_histogram(aes(fill = ..count..), color = &quot;#ccccaa&quot;) +
        scale_fill_gradient(&quot;Frequency&quot;, low = &quot;#5cb85c&quot;, high = &quot;#428bca&quot;) +
        facet_wrap(~ state) + 
        scale_x_log10() +
        theme_minimal() +
        theme(legend.position = &quot;bottom&quot;,
              legend.direction = &quot;horizontal&quot;)

p3 + p4</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="/walkthroughs/Hypotheses/Hypotheses_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Similar to the plots in the one-sample example, to test if the Ohio and Michigan averages differ we’ll perform two tests. Also, note that we am searching for any differences between the means rather than if one is specifically less than or greater than the other. First we test with a normal <em>t</em>-test without any distribution transformations. The results below show a <em>p</em>-value &lt; 0.01 supporting the alternative hypothesis that “true difference in means is not equal to 0”; essentially it states there is a statistical difference between the two means.</p>
<pre class="r"><code>t.test(percollege ~ state, data = ohio_mi)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  percollege by state
## t = 2.5953, df = 161.27, p-value = 0.01032
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.6051571 4.4568579
## sample estimates:
## mean in group MI mean in group OH 
##         19.42146         16.89045</code></pre>
<p>Again as an alternative, due to the non-normality concerns we can perform this test in another way to ensure our results are not being biased due to assumption violations. We can perform the <em>t</em>-test and transform our data. The results support our initial conclusion that the percent of college educated adults in Ohio is statistically different than the percent in Michigan.</p>
<pre class="r"><code>t.test(log(percollege) ~ state, data = ohio_mi)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  log(percollege) by state
## t = 2.9556, df = 168.98, p-value = 0.003567
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.04724892 0.23732151
## sample estimates:
## mean in group MI mean in group OH 
##         2.915873         2.773587</code></pre>
</div>
<div id="the-paired-t-test" class="section level3">
<h3>The Paired <em>t</em>-test</h3>
<p>To illustrate the paired <em>t</em>-test we’ll use the built-in <code>sleep</code> data set.</p>
<p>Please load up the following packages</p>
<pre class="r"><code>sleep</code></pre>
<pre><code>##    extra group ID
## 1    0.7     1  1
## 2   -1.6     1  2
## 3   -0.2     1  3
## 4   -1.2     1  4
## 5   -0.1     1  5
## 6    3.4     1  6
## 7    3.7     1  7
## 8    0.8     1  8
## 9    0.0     1  9
## 10   2.0     1 10
## 11   1.9     2  1
## 12   0.8     2  2
## 13   1.1     2  3
## 14   0.1     2  4
## 15  -0.1     2  5
## 16   4.4     2  6
## 17   5.5     2  7
## 18   1.6     2  8
## 19   4.6     2  9
## 20   3.4     2 10</code></pre>
<pre class="r"><code>ggplot(sleep, aes(group, extra, fill = group)) +
        geom_boxplot(alpha = 0.5) +
        scale_fill_manual(values = c(&quot;#00274C&quot;, &quot;#BB0000&quot;)) +
        theme_minimal() </code></pre>
<p><img src="/walkthroughs/Hypotheses/Hypotheses_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>In this case we are assessing if there is a statistically significant effect of a particular drug on sleep (increase in hours of sleep compared to control) for 10 patients. Please see <code>?sleep</code> for more details on the variables.</p>
<p>We want to see if the mean values for the extra variable differs between group 1 and group 2. Here, we perform the <code>t.test</code> as in the previous sections but just add the <code>paired = TRUE</code> argument:</p>
<pre class="r"><code>t.test(extra ~ group, data = sleep, paired = TRUE)</code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  extra by group
## t = -4.0621, df = 9, p-value = 0.002833
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -2.4598858 -0.7001142
## sample estimates:
## mean of the differences 
##                   -1.58</code></pre>
<p>In this example it appears that the drug does have an effect as the <span class="math inline">\(p\)</span>-value = 0.0028 suggesting that the drug increases sleep on average by 1.58 hours.</p>
<p>The above looks at exact matching. If you are getting an error, try running which will only run on values that can be matched. To use the command below, make sure both comparison variables are numeric.</p>
<pre class="r"><code>sleep &lt;- sleep %&gt;%
  mutate(group = as.numeric(group))

t.test(sleep$extra, sleep$group, paired = TRUE)</code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  sleep$extra and sleep$group
## t = 0.095569, df = 19, p-value = 0.9249
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.8360223  0.9160223
## sample estimates:
## mean of the differences 
##                    0.04</code></pre>
</div>
</div>
