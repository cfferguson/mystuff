---
title: "An Incomplete Survey of Fundamental Statistical Tests in R"
subtitle: "EDP 613: Fall 2020"
header-includes:
  - \usepackage[T1]{fontenc}
  - \usepackage{fontspec}
  - \setmainfont{Iwona Light}
  - \usepackage{makecell}
  - \usepackage{xcolor}
output: 
  pdf_document:
    latex_engine: xelatex
    includes:
      in_header: preamble.tex
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(tidy=FALSE, echo = TRUE, fig.pos = 'H')
library(htmltools)
library(kableExtra)
library(knitr)
options(knitr.table.format = "latex")
library(showtext)
font_add_google("Roboto Condensed", "roboto")
showtext_auto()
```

\newpage 

# Libraries

Please load up the following packages (or install and then load them as needed)

```{r}
library(tidyverse)
library(car)
library(foreign)
library(lme4)
library(MASS)
library(CCA)
library(psych)
```

```{r xml_library, include=FALSE}
library(xml2)
```

```{r get_table, include=FALSE}
webpage_url <- "https://stats.idre.ucla.edu/other/mult-pkg/whatstat/"
```

```{r table_parse, include = FALSE}
webpage <- xml2::read_html(webpage_url)
```

```{r tibble_table, include=FALSE}
WebTable<- rvest::html_table(webpage)[[1]] %>% 
  tibble::as_tibble(.name_repair = "unique") 
```

```{r select_table, include=FALSE}
StatsTable <- 
  WebTable %>%
  rename(`Type of Dependent Variables` = `Nature of Dependent Variable(s)*`) %>%
  rename(`Type of Independent Variables`= `Nature of Independent Variables`) %>%
  dplyr::select(-starts_with("How to")) %>%
  # add_column(Link = "") %>%
  filter(`Test(s)` != "")
```

# A Side Note About R

Fist of all, a big thank you for sticking with `R` even though it was rough at times. It may not be apparent, but developing coding skills like the ones in this course have benefits, not least of all in simply understanding the structure of a given data set. There are too many examples of students and even professionals who run an analysis on data without considering the data itself. `R` and other syntax-based software packages like it (yes even SPSS if you work with the underlying code) to their credit make you explore your data whether it be through checks or frustration.

While I agree that proprietary softwares such as SPSS, SAS, Minitab, etc. are easier to learn `R` (and Python) is open access (free) while proprietary softwares requires an expensive license. Picking on SPSS, users pay for the base package and then have to pay separately for any add-ons (such as predictive analytics, generate data from missingness, etc.) they want to use. Consider what would make you most marketable!

With that said, learning `R` is a lifelong process and assisting student learning and growth should never be confined to a single course so please FEEL FREE to contact me if you have questions regarding R (or Python if you go there) at any time. Again, I will always make time for students.

# Purpose

This walk-through will provide you with information on how to perform a number of statistical tests using R. Some of these will look familiar while others you will be exposed to in future statistics courses if that is your path. In either case, hopefully these will be helpful if for no other reason than to provide a check or confirmation of results.

# Decisions Decisions Decisions

When deciding which test is appropriate to use, it is important to consider the type of variables that you have. Please load in the following data sets (AND TAKE A LOOK AT THEM by using `View()` or `head()`)

```{r}
some_ed_data <- read_csv("some_ed_data.csv")
```

\newpage

```{r}
some_exercise_data <- read_csv("some_exercise_data.csv")
```

```{r}
some_survey_data <- read_csv("some_survey_data.csv")
```

The following table provides some basic information about data types. While I would love to have constructed this table and the syntax blocks thereafter, a majority of the information was scraped from the web using `R` via the [UCLA Institute for Digital Research & Education](https://stats.idre.ucla.edu/r/whatstat/what-statistical-analysis-should-i-usestatistical-analyses-using-r/) site using the `xml2` package. They also fully support SAS, SPSS (for those of you moving on to EDP 614), Stata, and Mplus. 

NOTE: I do not not receive compensation of any kind from the organization. With that said, it is an excellent resource so you may want to consider using it as a point of reference. 

# The (Not So) Ultimate Table
```{r, echo = FALSE, eval = TRUE}
kable(StatsTable, "latex", booktabs = TRUE, align = c("c", "l", "l", "l")) %>%
  kable_styling(latex_options = "striped", position = "center", full_width = TRUE) %>%
  column_spec(column = 1, width = "5em") %>%
  column_spec(column = 2:5, width = "11.5em") 
```

# Tests

## ANCOVA (Analysis of Covariance)
```{r}
summary(aov(some_ed_data$write ~ some_ed_data$prog + some_ed_data$read))
```


## Binomial test
```{r}
prop.test(sum(some_ed_data$female), length(some_ed_data$female), p = 0.5)
```


## Canonical Correlation
```{r}
cc(cbind(some_ed_data$read, some_ed_data$write), cbind(some_ed_data$math, 
                                                       some_ed_data$science))
```


## Chi-square ($\chi^2$) test
```{r}
chisq.test(table(some_ed_data$female, some_ed_data$schtyp))
```


## Chi-square ($\chi^2$) Goodness of Fit
```{r}
chisq.test(table(some_ed_data$race), p = c(10, 10, 10, 70)/100)
```


## Correlation
```{r}
cor(some_ed_data$read, some_ed_data$write)

cor.test(some_ed_data$read, some_ed_data$write)
```


## Discriminant analysis
```{r}
fit <- lda(factor(some_ed_data$prog) ~ some_ed_data$read + 
             some_ed_data$write + some_ed_data$math, data = some_ed_data)

fit
```


## Factor analysis
```{r}
fa(r = cor(model.matrix(~read + write + math + science + socst - 1, 
                        data = some_ed_data)), rotate = "none", fm = "pa", 2)
```


## Factorial ANOVA (Analysis of Variance)
```{r}
anova(lm(write ~ female * ses, data = some_ed_data))
```


## Factorial Logistic Regression
```{r}
summary(glm(female ~ prog * schtyp, data = some_ed_data, family = binomial))
```


## Friedman test
```{r}
friedman.test(cbind(some_ed_data$read, some_ed_data$write, some_ed_data$math))
```


## Kruskal Wallis test
```{r}
kruskal.test(some_ed_data$write, some_ed_data$prog)
```


## McNemar test
```{r}
# Here is some made up data in matrix form
made_up_matrixdata <- matrix(c(150, 22, 21, 12), 2, 2)
mcnemar.test(made_up_matrixdata)
```


## Multiple Regression
```{r}
lm(some_ed_data$write ~ some_ed_data$female + some_ed_data$read + 
     some_ed_data$math + some_ed_data$science + some_ed_data$socst)
```


## Multiple Logistic Regression
```{r}
glm(some_ed_data$female ~ some_ed_data$read + some_ed_data$write, 
    family = binomial)
```


## Multivariate Multiple Regression
```{r}
mmrlm <- lm(cbind(write, read) ~ female + math + science + socst, 
            data = some_ed_data)

summary(Anova(mmrlm))
```


## Non-parametric Correlation
```{r}
cor.test(some_ed_data$read, some_ed_data$write, method = "spearman")
```


## One Sample *t*-test
```{r}
t.test(some_ed_data$read, mu = 50)
```


## One-way ANOVA (Analysis of Variance)
```{r}
summary(aov(some_ed_data$read ~ some_ed_data$prog))
```


## One-way MANOVA (Multivariate Analysis of Variance)
```{r}
summary(manova(cbind(some_ed_data$read, some_ed_data$write, some_ed_data$math) ~ 
                 some_ed_data$prog))
```


## One-way Repeated Measures ANOVA (Analysis of Variance)
```{r}
model <- lm(gender ~ item_1 + item_2, data = some_survey_data)

analysis <- Anova(model, idata = factor_surveydata, idesign = ~s) 

print(analysis)
```


## Ordered Logistic Regression
```{r}
# Create ordered variable write_more as a factor with levels 1, 2, and 3
some_ed_data$write3 <- cut(some_ed_data$write, c(0, 48, 57, 70),  right = TRUE, 
                           labels = c(1,2,3))

table(some_ed_data$write3)

# fit ordered logit model and store results 'some_write_data'
some_write_data <- polr(write3 ~ female + read + socst, data = some_ed_data, 
                        Hess=TRUE)

summary(some_write_data)
```


## Paired *t*-test
```{r}
t.test(some_ed_data$write, some_ed_data$read, paired = TRUE)
```


## Principal Components Analysis
```{r}
princomp(formula = ~read + write + math + science + socst, 
         data = some_ed_data)
```


## Repeated Measures Logistic Regression
```{r}
glmer(highpulse ~ diet + (1 | id), data = some_exercise_data, 
      family = binomial)
```


## Simple Linear Regression
```{r}
lm(some_ed_data$write ~ some_ed_data$read)
```


## Simple logistic regression
```{r}
glm(some_ed_data$female ~ some_ed_data$read, family = binomial)
```


## Two independent samples *t*-test
```{r}
t.test(some_ed_data$read ~ some_ed_data$female)
```


## Wilcoxon-Mann-Whitney Test
```{r}
wilcox.test(some_ed_data$read ~ some_ed_data$female)
```


## Wilcoxon Signed Rank Sum Test
```{r}
wilcox.test(some_ed_data$write, some_ed_data$read, paired = TRUE)
```

\newpage
# A Final Rant About Open Source versus Proprietary 
There are so many others like those dealing with Structural Equation Modeling (SEM) and a special case of this approach: Higher Linear Modeling (HLM), Machine Learning (ML) and Predictive Modeling (nope ML is NOT [glorified statistics](https://www.nature.com/articles/nmeth.4642)!), etc. Those softwares and add-ons become expensive as the methodology becomes specialized and companies/institutions/organizations are less likely to purchase them. If you want to be truly marketable and versatile, become proficient with an open-source software like `R` and `Python`. It will be worth it!

## Side note
If you are a fan of the show Rick & Morty, consider downloading the most pointless package `mortyr` to do pointless statistics on pointless data. More about the package [here](https://github.com/mikejohnpage/mortyr). 

If you're feeling confident, you can program an "AI" write its own pointless [script](https://medium.com/dsc-manipal/generating-rick-and-morty-episodes-2413b608cd5) of the show.



